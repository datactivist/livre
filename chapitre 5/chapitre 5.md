Title: Open data : le contre pouvoir des données  
Author: Samuel Goëta  
Base Header Level: 1

## Des promesses démesurées de croissance et d'innovation ##

De grands cabinets de prospective et des institutions comme la Commission européenne ont promis des retombées économiques de l’ordre de plusieurs dizaines de milliards d’euros chaque année qui découleraient de la réutilisation des données publiques ouvertes.    

Ces promesses d’un « nouveau pétrole » qui stimulerait l’innovation et la croissance se sont révélées irréalistes au regard des résultats empiriques des études qui ont évalué l’impact de l’ouverture des données. Même si on note quelques *success-stories* découlant de la réutilisation de données ouvertes dans le domaine des transports et des services pratiques, le faible impact qu’on a pu observer sur l’économie a pu susciter une certaine déception pour les acteurs politiques qui ont misé sur l’open data pour créer des emplois. Cette déception risque à terme de mettre en péril les projets d’ouverture de données qui sont très dépendantes à leurs attaches politiques.        

Au-delà de l’aspect irréaliste des promesses de croissances liées à l’open data, le faible impact économique s’explique aussi par les difficultés des usagers à exploiter les données ouvertes. En effet, les données se révèlent souvent soit manquantes soit introuvables soit inutilisables quand elles sont disponibles. Nombreux sont les cas où les usagers se plaignent de la faible documentation des données et des incohérences des fichiers mis à disposition. Les données ouvertes sont, à ce stade, généralement pas assez fiables et trop parcellaires pour permettre la création de services, d’entreprises et d’emplois pérennes.  

### Le "nouveau pétrole" : des conjectures de croissance et d'emploi disproportionnées ###
        
La décision de mettre en oeuvre des politiques d’open data n’est pas née seulement de la volonté de renforcer la transparence de l’action publique. Dans les cas que j’ai étudiés dans le cadre de ma thèse, cet argument constituait plutôt un repoussoir pour les élus qui préfèrent éviter que les données mises à disposition par l’administration puissent servir à contester leur action et à renforcer l’opposition. Par exemple, lors d’une réunion entre des militants locaux de l’ouverture des données et un élu d’un conseil régional visant à discuter d’une éventuelle politique d’open data régionale, l’argument de la transparence a été totalement rejeté par l’élu qui ne voulait pas en entendre parler malgré les nombreux discours de l’éxécutif régional sur la démocratie participative et le renforcement de la vie citoyenne locale. L’argument, dans cette réunion et dans la plupart des cas que j’ai étudiés, qui emportait la décision des élus était la promesse de développement économique et de création d’emploi qui pourrait découler de la réutilisation des données publiques. Avant de détailler les fondements de cette promesse, il faut rappeler le contexte dans lequel les principes de l’open data sont apparus et ont été traduits en politiques publiques nationales et locales.

        

Comme nous l’avons vu dans le deuxième chapitre, le concept d’open data a été popularisé à partir de la fin de l’année 2007 aux Etats-Unis puis partout dans le monde. La rencontre fondatrice de Sebastopol est intervenue quelques mois après le lancement de l’iPhone en juin 2007 et avant la création en juin 2008 de l’App Store d’Apple, une des premières plateformes de services mobiles qui a généré des revenus conséquents pour les développeurs d’applications mobile. La création de services mobiles est alors apparue comme une des nouvelles frontières de l’économie numérique ; ouvrir les données de l’administration permettrait de créer une multitude de nouveaux services pratiques. Il faut aussi rappeler le contexte de la crise économique à partir de l’autonme 2018 qui incite les acteurs publics à mobiliser toutes les ressources disponibles pour favoriser la relance de l’économie. Les promesses de croissance formulées dans les études macroéconomiques sur l’impact économique de l’open data ont pu appâter de nombreux élus. Enfin, l’organisation en 2008 du concours *Apps for Democracy* \{Demeyer:2012uy\} a inspiré le développement de nombreux concours d’application réutilisant des données ouvertes. Les organisateurs d’Apps for Democracy ont créé un guide pour l’organisation de concours d’application ou de hackathon et ont insisté sur les retombées économiques de l’évènement de 2008, la valeur des 47 applications créées étant estimée à 2 300 000 $ pour un coût de l’opération de 50 000 $. Cette estimation, très fréquemment reprise comme preuve du potentiel économique de l’open data, repose sur un judicieux calcul qui multiplie le coût de développement évalué à 50 000$ par application pour déterminer la valeur crée lors du concours. Or, la valeur n’équivaut pas nécessairement au coût ; elle dépend principalement du marché et de l’utilité du bien. Cette valeur a été largement sur-évaluée et a contribué à l’essaimage des évènements comme les hackathons dans lequel les  « hackers civiques » \{Coleman:2013uk\} sont incités à réutiliser des données ouverte sur une période courte de compétition. 

        

Dans ce contexte, les études macroéconomiques se sont multipliées pour tenter d’évaluer l’impact potentiel de l’ouverture des données. Un des premiers acteurs à avoir effectué de telles analyses est Rufus Pollock, le fondateur de l’Open Knowledge Foundation et chercheur en économie à l’université de Cambridge, a modélisé les retombées économiques de l’open data en comparaison des revenus que les administrations pouvaient tirer des redevances. Il a montré que les redevances réduisent la demande alors que la réutilisation gratuite (ou au moins au coût marginal) réduisent les barrières à l’entrée et démultiplient l’impact économique des données publiques, les services créés générant des recettes fiscales bien supérieures au manque à gagner des redevances \{Pollock:2008ui, Trojette:2013wr\}. Ces évaluations de la valeur économique de la libre réutilisation des données publiques ont figuré au coeur de l’argumentaire de l’Open Knowledge Foundation. A la suite de la directive sur les informations du secteur public de 2003, l’Union Européenne a encouragé les évaluations du potentiel économique de l’open data avec une première étude en 2006 qui évaluait l’impact entre 26 et 48 millions d’euros. L’Union évaluait en 2017 à 59 milliards d’euros le marché de la production et du traitement des données et estimait que cette industrie emploie six millions de citoyens européens, des chiffres qui devraient presque doubler d’ici 2020[^fn1]. Pour l’Union, les données ouvertes constituent un carburant de l’industrie plus large des données dont il faut encourager l’ouverture la plus large. 

        

Sous l’impulsion notamment de la Commission Européenne et d’institutions internationales comme la Banque Mondiale, les études macro-économiques se sont multipliées à partir de 2010 mais on constate des écarts considérables dans la manière dont elles évaluent l’impact de l’open data. Une étude réalisée pour le portail européen de données[^fn2] a montré des écarts de 1 à 10 entre les différentes évaluations de la valeur de l’open data (figure *2*) : la valeur économique des données ouvertes variant entre 0,4% et 7% du PIB mondial ! 

![][Capturedécran2018-08-27à185034]

*Figure 2. Synthèse des études évaluant la valeur économique de l’open data exprimée en pourcentage du PIB mondial.* 

        

Comment expliquer de telles variations ? L’étude du portail européen de données évoque d’abord les différences de méthode d’évaluation : certaines ont une approche « par le haut » en modélisant la part des données ouvertes dans la chaine de création de valeur macroéconomique tandis que d’autres études partent « du bas »  en évaluant l’impact de l’open data de manière sectorielle puis généralisent à l’ensemble de l’économie. Ces évaluations sont généralement des études *ex-ante*, effectuées à partir de recherche et de modélisation, plutôt qu’*ex post* en mesurant l’impact économique constaté d’une mesure. Elles sont donc des prévisions plutôt que des mesures objectives. D’autre part, les études varient dans leurs sources de données : certaines se concentrent sur les données du secteur public tandis que d’autres les données de la recherche et celles du secteur privé. Les évaluations ne sont pas accordées sur la définition même de l’open data et considèrent que certaines données qui ne sont pas librement ouvertes mais partagées à des acteurs sélectionnés selon des conditions restrictives peuvent entrer dans l’estimation de valeur. Enfin, dans l’évaluation des bénéfices, certaines études incluent des externalités environnementales ou sociales indirectes selon les méthodes de l’analyse cout-bénéfices qui traduit de manière monétaire tous les aspects de la vie \{Robert:2000wn, Ackerman:2002ux\}. Cela crée une confusion majeure puisque la valeur de l’open data est souvent exprimée en pourcentage du PIB alors que certaines études font une équivalence monétaire à des phénomènes qui ne contribuent pas directement à la création de valeur économique. 


Malgré les variations et les limites méthodologiques de ces études que nous venons de voir, la fourchette haute est généralement retenue lorsqu’il s’agit d’évaluer la valeur économique de l’open data. Même si elles restent utiles pour emporter la décision des élus et servir de justification aux politiques d’open data, ces estimations ont aussi des effets délétères lorsqu’est venu le moment d’évaluer l’impact réel sur l’économie. C’est particulièrement vrai au niveau local où les élus ont dédié des moyens à l’open data en espérant des retombées directes en terme de croissance et d’emploi sur le territoire. Or, comme nous allons le voir, les créations d’emploi et d’entreprises réutilisant des données ouvertes, encore plus locales, sont encore assez rares. 

### Un impact en déça des attentes de création d'emploi ###
        
Il ne s’agit pas dans cette section de refaire une étude macroéconomique car ce n’est pas dans mes compétences et que les résultats que je pourrai afficher seraient encore plus contestables que les études que j’ai évoquées précédemment. Néanmoins, il me paraît essentiel dans ce bilan critique  de faire part d’une déception qu’évoquent de nombreux acteurs publics ayant ouvert des données à l’égard de l’impact économique de l’open data. Ces déceptions sont aussi fortes que les promesses d’un nouveau pétrole ou d’une nouvelle manne pour les territoires qui ont été formulées par certains défenseurs de l’open data avides de chiffres grandiloquents. Mais si on s’intéresse aux résultats en terme d’emplois découlant de l’ouverture des données publiques, on s’aperçoit d’un certain décallage entre les chiffres annoncés et la réalité des créations d’emplois dans les sociétés réutilisant des données. Dans les données qualitatives de l’Open Data Barometer 2018 qui servent à justifier du classement de la France parmi les pays ouvrant officiellement des données, une des questions porte sur les créations d’emplois. Dix sociétés employant entre cinq et trente personnes, y sont citées car leur modèle économique est fondé sur l’open data à différents stades de la chaine de valeur. Ce recensement, qui n’est pas aussi exhaustif, contraste avec les chiffres de création d’emploi avancés en particulier par l’Union Européenne pour inciter les organisations publiques à ouvrir leurs données. Selon le rapport *Creating Value through Open Data* commandé par la Commission Européenne et publié en 2015[^fn3], l’ouverture des données publiques devrait avoir créé 80 000 emplois en 2018 dans l’Union. Parmi ces 80 000 emplois, environ 9600 emplois devraient être créés en France si on suit la répartition des *data jobs* dans une autre étude européenne[^fn4]. Or, cette estimation doit être prise avec des pincettes. Le rapport du Portail Européen de Données précédemment cité explique ce chiffre est fondé sur la généralisation à l’ensemble de l’Union d’une estimation réalisée en Espagne  : 

Alors que l’open data est placé de plus en plus haut dans les agendas politiques des pays en Europe et au-delà, et avec de plus en plus d’organisations conduisant des évaluations, ce nombre devrait être mis à jour, comme les nombres devraient être basés sur une étude espagnole évaluant le nombre d’emplois directs estimant le nombre d’emplois directs dans le secteur des infomédiaires espagnols à un niveau de 4200-4700 emplois. \[...\] Cependant, la définition du secteur des infomédiaires observé dans l’étude espagnol est légèrement plus large que la part des entreprises qui ont un modèle économique basé sur l’open data. Cette mise en garde implique de prendre des précautions à l’égard de cette estimation. 

La création de 9600 emplois en France et 80 000 emplois en Europe grâce à l’ouverture des données publiques est en fait fondé sur la généralisation d’une étude espagnole dont le périmètre dépasse largement les données ouvertes. Il est très propale que cette étude englobe toutes les entreprises réutilisant des informations du secteur public, une industrie ancienne qui a su obtenir les données dont elle avait besoin soit par la redevance soit par des accords d’exclusivité. Cette estimation concerne donc en grande partie des entreprises existant de longue date dont le modèle économique n’est pas fondé sur les jeux de données mis à disposition du fait des politiques d’open data. Cela explique le décalage entre les données qualitatives sur les entreprises réutilisant en France des données publiques et les chiffres retenus par l’Union Européenne et acceptés par tous les décideurs et jamais questionnés par les journalistes. En soi, ces chiffres au fondement opaque sont courants dans le débat public mais ils posent problème lorsqu’ils fondent une politique. En effet, lorsque les décideurs questionnent les résultats effectifs de l’open data sur l’emploi, il est difficile de faire la démonstration des emplois créés. Dans certaines collectivités locales en particulier, cela a créé au mieux de la déception ; au pire, cela a marqué un coup d’arrêt à plusieurs projets d’open data après quelques années de recul.


Même s’il faut donc prendre ces estimations macroéconomiques avec précaution, on peut déjà identifier quelques fleurons parmi les entreprises ouvant ou réutilisant des données publiques françaises. L’étude européenne *Creating Value through Open Data* identifie quatre étapes dans la chaine de valeur de l’ouverture et de la réutilisation des données publiques (figure 3)  : la création, l’agrégation, l’analyse et le développement de services. 

![][Capturedécran2018-09-06à220408]

Figure 3. Illustration de la chaine de valeur de l’open data.  



A travers ces quatre étapes, on trouve des entreprises françaises qui ont créé des emplois et développé des services autour de l’open data qui sont utilisées internationalement. Dans la première phase, celle de la fourniture des données, on peut citer OpenDataSoft, aujourd’hui un des leaders des portails d’ouverture et de partage de données. Leur solution propose pour chaque jeu de données une interface de programmation (API) permettant de développer des services automatisés à partir des données ainsi que des fonctionnalités de visualisation et de cartographie avancées. La société compte aujourd’hui près de 60 salariés dont huit aux Etats-Unis et a levé en octobre 2016 5 millions d’euros. Dans le domaine de la culture et du tourisme, Open Agenda emploie quatre salariés et propose une solution d’agendas partagés dont les données sont ouvertes et standardisées. Dans la deuxième phase, celle de l’agrégation de données, Navitia (filliale de Kisio, elle-même filiale de Keolis) agrège les données des horaires de 1600 réseaux de transport dans 25 pays. Comoprices, une autre société française, aggrège les données sur les prix de près de 3000 matières premières et propose des outils d’analyse pour les négociateurs. DBNomics tente de regrouper toutes les données sur l’économie internationale. Concernant la troisième phase, celle de l’analyse des données, il serait trop laborieux de citer ici toutes les sociétés spécialisées en *data science* qui ont les capacités d’étudier les données ouvertes. Certaines comme Snips ou Nam.r ont attiré des investissements conséquents et se sont spécialisés dans l’analyse de données ouvertes. Enfin, concernant la quatrième phase de création de services, les produits fondés sur la réutilisation de données ouvertes ne manquent pas. On peut toutefois citer deux sociétés françaises dont les services sont devenus des références à l’international. Plume, une application qui agrège les données sur la pollution de l’air dans plus de 3000 villes dans le monde et aide les usagers à trouver le meilleur moyen pour faire une activité en plein air selon l’état de l’air. Yuka s’appuie sur les données ouvertes par les contributeurs d’OpenFoodFacts (nous en reparlerons dans le chapitre 7) et propose une application qui donne des recommandations alimentaires pour chaque produit scanné par son code barre. Sur la base de données locales, une multitude de services ont été créés mais ils peinent à s’étendre du fait du manque d’interopérabilité des données ouvertes par les collectivités locales. Chaque jeu de données de chaque territoire répond généralement à un modèle de données différent et comporte rarement les mêmes caractéristiques. Par exemple, Handimap (une application d’itinéraires urbains en fauteuil roulant) et Geovélo (un service qui détermine les itinéraires à vélo selon la cyclabilité des voies) ont développé pour chaque ville partenaire une nouvelle application du fait que les données ne sont jamais harmonisées selon les villes. Autre exemple, QuiDitMiam, qui propose une application pour présenter aux parents les menus des cantines scolaires, demande aux villes d’harmoniser via son outil les données des menus mais cela demande un travail conséquent et limite le développement de ce service. 

        

Ces exemples n’ont pas vocation à faire un recensement exhaustif des entreprises nées des données ouvertes mais à montrer qu’il existe déjà bon nombre de sociétés qui se sont saisies des données ouvertes. Même si ces exemples sont vraisemblablement en deça des promesses de création d’emploi et de valeur, rappellons que l’open data est un mouvement récent qui peut mettre plusieurs décennies à porter ses fruits et que des acteurs économiques réutilisent des données ouvertes sans que cela ne soit visible pour le producteur de données ni pour l’usager du service. Un grand nombre de services réutilisant des données ouvertes passe ainsi sous le radar du fait du principe de *non-registration* (pas d’identification) qui est aujourd’hui dans les normes de l’open data. Si ce principe garantit aux usagers qu’ils ne seront pas discriminés selon la finalité de leur usage, il empeche à l’administration de connaitre les usagers de ses données et entrave le dialogue avec les usagers. Sans remettre en cause le principe de non identification, on peut imaginer un système inspiré des marchés publics dans lequel le réutilisateur a le choix entre télécharger les données anonymement ou s’inscrire pour recevoir des mises à jour et faire part de ses retours à l’administration. 

### Des données souvent introuvables et mal documentées ###
        
Même si l’open data a permis de créer plusieurs entreprises et a déjà généré de la valeur, ces exemples sont limités dans leur impact macro-économique et se pose la question de la montée à l’échelle de ses sociétés. Si l’on interroge les réutilisateurs, réutiliser des données ouvertes pour créer une activité économique est très complexe du fait d’abord d’un manque de la difficulté d’identifier les données disponibles et librement réutilisables sur un sujet. Ce problème de la découvrabilité des données ouvertes a été pointé au niveau international dans le dernier rapport du classement Open Data Index d’Open Knowledge International[^fn5]. 

La découvrabilité des données est un défi majeur. Nous avons des portails et des registres de données mais les agences d’un seul gouvernement national continuent de publier des données de manières différentes et à différents endroits. De plus, elles ont différents protocoles pour les licences et les formats. Cela a un impact hasardeux : nous pouvons ne pas trouver des données ouvertes, même si elles sont en ligne et donc nous ne pouvons pas les utiliser. La découvrabilité des données est un pré-requis pour que l’open data réalise son potentiel et actuellement la plupart des données sont très difficiles à trouver. 

Concrètement, trouver des données peut se révéler être un parcours du combattant même pour des usagers experts. Mon associé dans Datactivist, Joël Gombin, a fait ses recherches pendant près d’une décennie en sociologie électorale à partir de données ouvertes sur les élections mais aussi d’autres phénomènes socio-économiques. Interrogé pour une recherche sur usagers de [data.gouv.fr](http://data.gouv.fr) réalisé pour Etalab[^fn6], il a expliqué que généralement le jeu de données recherché est souvent noyé dans les résultats. Par exemple, pour une recherche « élections présidentielles » sur [data.gouv.fr](http://data.gouv.fr), le classement n'est pas compréhensible : le premier jeu de données correspond à des élections municipales, le quatrième à des élections européennes puis arrivent ensuite des jeux relatifs aux élections cantonales et aux élections législatives. Enfin, arrive en 8ème position un jeu mentionnant explicitement élections présidentielles. Ces problèmes de découvrabilité ont heuresement été résolus par l’équipe d’Etalab suite à cet entretien. Mais ils ne sont pas uniquement liés à un mauvais fonctionnement de la recherche recherche des portails, on les retrouve sur les moteurs de recherche généraliste comme Google. Le cartographe Jules Grandin avait aussi pointé du doigt ce problème dans un tweet « rechercher des données : une déception en 4 actes » illustré de quatre captures d’écran. Il a d’abord fait une recherche « comptage voyageurs rer » sur Google, cliqué sur le premier résultat issu de [data.gouv.fr](http://data.gouv.fr).  Sur le portail, la fiche de description du jeu de données (seize mots) semble correspondre à sa demande. Il télécharge le fichier et l’ouvre dans un tableur pour découvrir un fichier de deux lignes et deux colonnes comportant uniquement une seule valeur pour la ligne B dans une période temporelle non déterminée. Ouvrir un tel fichier inutilisable ne peut qu’entrainer de la déception et décourager les usagers potentiels de se rendre de nouveau sur un portail open data.     

Ce cas illustre un deuxième grand problème rencontré par les usagers, celui de la documentation des données ouvertes. Ce point reboucle avec le précédent : si le jeu de données est décrit de manière lacunaire, les moteurs de recherche auront des difficultés à renvoyer des résultats pertinents. Mais surtout la documentation est essentielle pour que les usagers comprennent le contenu des données et soient en capacité de les utiliser. Pour comprendre l’importance de la documentation, il peut être utile de faire un pas de côté car ce sujet a déjà été grandement étudié en sciences humaines par les *Science and Technology Studies* (STS) qui proposent des ressources essentielles pour mieux comprendre les enjeux de la production de métadonnées \{Baker:2007bw, Millerand:2009us, Zimmerman:2008eu, Edwards:2011kx\}. Ces travaux d’études des sciences montrent que la réutilisation des données implique un travail complexe de coordination qui passe souvent par des interactions directes avec leurs producteurs initiaux. Comment avez-vous mesuré ? Où se trouvaient les sondes ? Pourquoi y a-t-il une valeur étonnante ici ? Et pourquoi manque-t-il des valeurs sur cette colonne ? Pourquoi les unités de mesure changent-elles entre ces deux années ? Ces questions qui peuvent paraitre triviales sont en fait vitales à la réussite d’un projet fondé sur le partage de données. Plutôt que d’institutionnaliser ces interactions, la solution a consisté à investir dans des « métadonnées », censées apporter toutes les informations nécessaires à la compréhension et l’appropriation des données initiales. Les travaux en STS ont montré que le partage et la réutilisation des données provoquent des « frictions » \{Edwards:2010vs\}, des tensions et des difficultés que seul travail considérable partagé entre les producteurs et les réutilisateurs de données parvient à diminuer. Si on considère les métadonnées comme les seules ressources nécessaires au partage efficace de données, cela ne fait qu’ajouter des *metadata frictions*. Le fantasme d’une description transparente et complete des données se traduit donc concrètement par un travail supplémentaire d’ancrage et de contextualisation \{Edwards:2011kx\}. L’étude des sciences nous montre donc que le partage des données ne peut se réaliser sans que producteurs et réutilisateurs ne se coordonnent. Les métadonnées aussi sophistiquées et complètes soient-elles ne suffisent pas à résoudre les problèmes que rencontrera un usager en exploitant des données. Mais, en ce qui concerne les données publiques ouvertes, les métadonnées qui décrivent le contenu et le processus de production des données ouvertes sont généralement complétées de manière très lacunaire. Pourtant, les préconisations officielles et les principes de l’open data mettent un point d’honneur à la production de métadonnées complètes comme l’illustre cet extrait de la charte internationale de l’open data[^fn7] : 

Nous veillerons à ce que les données soient décrites de manière complète, que toute la documentation accompagnant les données soit rédigée dans un langage clair et simple et que les utilisateurs disposent de suffisamment d’information pour comprendre les sources, les points forts et les points faibles et les limites analytiques des données;

Passées les déclarations d’intention, la documentation des données se révèle dans les faits beaucoup plus lacunaire. Dans l’immense majorité des cas, les descriptions des jeux de données dans les métadonnées sont très courtes. Ce constat quotidien restait à objectiver. Dans le cadre projet tutoré avec des étudiants, nous avons analysé les catalogues de données de 12 des 16 plus grandes villes de France pour le projet de recensement des données urbaines publié par Datactivist[^fn8]. Nous nous sommes intéressés à la longueur du champ description dans les métadonnées produites ce qui nous a révélé que la moitié des descriptions des jeux de données fait moins de 180 caractères et que 4% des jeux de données ont une description supérieure à 1000 caractères soit une demi-page.   

Dans les faits, il faut donc généralement composer avec des descriptions des jeux de données très courtesqui pourraient tenir dans un ou deux tweets. Souvent, les descriptions sont une reformulation du titre du jeu de données. Pour les jeux de données les plus réutilisés, les frictions de la réutilisation des données sont fluidifées par les échanges directs rendus possibles par certains portails en particulier [data.gouv.fr](http://data.gouv.fr). Pour faire face aux nombreuses sources de frictions que génère l’exploitation de données ouvertes, les usagers doivent pouvoir échanger entre eux et obtenir un retour de l’administration sur les données. Sur data.gouv.fr, il n’est pas rare que la documentation des données soit beaucoup plus riche dans les discussions que dans les métadonnées officielles comme c’est le cas par exemple pour la base des accidents de la route du ministère de l’Intérieur.

Mais il est aussi fréquent que les producteurs de données ne répondent pas aux questions posées par les usagers ce qui limite les possibilités d’amélioration de la documentation et des données. Cet espace d’échange autour de chaque jeu de données est parfois même fermé, en particulier sur les portails des collectivités locales. Dans les 16 villes étudiées dans le recensement conduit par Datactivist, seules 6 ont ouvert la possibilité d’ouvrir un fil de commentaires pour chaque jeu de données. De ce fait, il n’y a pas de possibilité d’entraide entre les usagers ou de mise en valeur des échanges qui peuvent avoir lieu entre la communauté et les réutilisateurs. Ces échanges sont pourtant essentiels pour fluidifier les frictions inévitables lors de la réutilisation de données produites dans un contexte inconnu comme nous l’ont enseigné les travaux qui se sont penchés sur le partage de données en science. 

### Des données pas encore assez fiables pour créer des services pérennes ###
        
Pour beaucoup d’usagers, les données ouvertes présentent de graves problèmes de qualité. Cette critère récurrente de la qualité des données doit être prise avec des précautions. En effet, les principes de l’open data ont constamment insisté sur l’importance de publier les données brutes, sans que les producteurs n’aient à les retravailler afin de ne pas causer de travail supplémentaire aux agents et de disposer du matériau brut de l’information publique, des données telles qu’elles sont utilisées par l’administrations. D’autre part, rappellons que les politiques d’open data ont permis la libre réutilisation des données de gestion qui servent au travail quotidien de l’administration, qui n’ont pas été conçues pour circuler hors des services qui assuraient leur production et leur traitement. Dans ces conditions, l’ouverture met à l’épreuve des données qui, publiées telles quelles, peuvent être considérées comme de mauvaise qualité, alors même qu’elles sont satisfaisantes du point de vue de leurs usages internes. Cherchant pourquoi les dossiers médicaux qu’ils étudiaient dans leurs recherches étaient de si mauvaise qualité, Garfinkel et Bittner \{Garfinkel:1967vp\} ont montré qu’il existe de nombreuses « bonnes raisons organisationnelles » pour que ces données persistent et soient même considérées comme précieuses. Les données sont ancrées dans des pratiques professionnelles particulières ; leur confrontation potentielle avec des domaines d’activité qui n’ont aucun rapport avec leur ancrage initial risque de résulter dans leur stigmatisation. Des données auxquelles personne n’a jamais rien eu à reprocher peuvent se retrouver qualifiées d’impropres à l’usage     

Même s’il est indispensable de rappeler que les données disponibles en open data n’avaient pas été précédemment mise à l’epreuve de leur diffusion, les problèmes rencontrés par les réutilisateurs sont réels et entravent le développement d’entreprises pérennes à partir de données. Le data scientist Vincent Brouté a synthétisé un condensé des difficultés que peuvent rencontrer des réutilisateurs face à des données ouvertes[^fn9]. Après avoir exploité les données d’Infogreffe concernant les créations, les radiations et les chiffres clés des entreprises, il a publié un «  mémorandum sur ce qu’il ne faut pas faire en Open Data » listant les différents problèmes qu’il pu rencontrer en utilisant ces données. Déjà, la structure des données d’Infogreffe évolue d’année en année ce qui empêche un import automatique des données et demande une intervention manuelle pour constituer une base sur l’ensemble de la période pour laquelle des données sont disponibles. Des colonnes disparaissent certaines années (le secteur d’activité est renseigné uniquement de 2012 à 2015), d’autres sont renommées au fil des années (« date immatriculation » devient « date d’immatriculation » ou « effectif 2013 » passe au pluriel l’année suivante « effectifs 2014 » ) ou certaines sont créées comme le numéro de département à partir de 2015. Les fichiers comportent aussi des abérations : dans les fichiers annualisés, une entreprise est passée ainsi de 3 à 303 387 salariés en 2015 et une autre a réussi la prouesse de générer plus de quatre milliards d’euros de résultat net en 2015 pour un chiffre d’affaires de 10 000€. De manière similaire, les coordonnées géographiques aussi concentrent les 355 entreprises radiées en 2015 à Rennes sur le même point, 126 codes postaux font moins de cinq caractères (c’est impossible). Plus préoccupant : la date de radiation diverge dans un tiers des cas selon si elle est présentée en une seule colonne (année-mois-jour) ou en trois colonnes pour chacune de ces dimensions. Ces problèmes pourraient être perçus comme une conséquence normale de la confrontation de données qui n’étaient précédemment pas diffusées à de nouveaux contextes. Mais les données d’Infogreffe ont jusqu’en 2017 étaient commercialisées et les producteurs de ces données ont pour métier de garantir la qualité de l'information juridique et financière sur les entreprises, les greffiers devant assurer l'authenticité des actes de la juridiction dont ils sont les conservateurs. L’exposition des données distribue la détection des erreurs et des problèmes contenus dans les données, un bénéfice indirect de l’ouverture des données pour l’organisation. Or, les problèmes signalés par Vincent Brouté n’ont dans l’ensemble pas été pris en compte un an et demi après la publication de son billet si ce n’est quelques colonne parasites, des colonnes dont le nommage ou la documentation ne permettent pas de savoir ce qu’elles contiennent, qui ont été supprimées. Les données comportent une documentation quasi inexistante, chaque base étant accompagnée d’une quinzaine de mots décrivant les données reprenant souvent les termes du titre. Enfin, Vincent Brouté signale qu’il n’y a aucun espace public (commentaires ou forum) sur lequel les utilisateurs peuvent poser des questions aux producteurs ou discuter de leurs difficultés avec d’autres utilisateurs. Seul un formulaire de contact est disponible mais il semblerait que les réponses soient rares. 

Pour répondre aux difficultés de réutilisation que rencontrent les usagers des données ouvertes, l’article 14 de la loi pour une République numérique a prévu la création du service public de la donnée qui vise à « sécuriser les utilisateurs et leur garantir une qualité de service de niveau industriel » pour les données de référence, celles qui ont le plus d’impact économique et social et dont la qualité de mise à disposition est critique pour les utilisateurs[^fn10].  Ces données de référence sont des informations publiques qui permettent de nommer ou d’identifier certains produits, services, territoires ou personnes et leur niveau de réutilisation nécessite qu’elles soient mises à disposition avec un niveau élevé de qualité \{Mouriesse:2018ti\}. Neuf jeux de données ont rejoint par décret le service public de la donnée suite à une consultation : la base SIRENE des entreprises et de leurs établissements, la base adresse nationale, la base de l’organisation administrative de l’Etat, le répertoire national des associations, le plan cadastral informatisé, le référentiel à grande échelle, le répertoire opérationnel des métiers et des emplois, le code officiel géographique et le registre parcellaire graphique. Ces données doivent répondre aux trois principes essentiels du  service public d’égalité d’accès, de continuité avec une disponibilité des données en téléchargement de 99% du temps mensuel garanti par décret et de mutabilité, les données devant suivre les besoins des usagers ainsi que les évolutions techniques. Une procédure de signalement permet aux utilisateurs de signaler que les données postées sont incomplètes ou erronées, l’arrêté qui définit les règles du service public de la donnée prévoit que l’administration a un mois pour répondre à la demande de l’usager. L’absence de réponse peut être contestée dans le cadre d’un recours pour excès de pouvoir devant le juge administratif ce qui octroie aux usagers un véritable « droit de regard » sur la manière dont les données sont mises à disposition. Etalab réfléchit actuellement à l’extension du service public de la donnée, prévoyant d’identifier avec la communauté deux à trois jeux de données essentiels par ministère[^fn11]. Cette démarche va dans le bon sens puisqu’elle permet de faire basculer progressivement les politiques d’open data d’une politique de l’offre à une politique de la demande. Contrairement à l’idéal des grands principes de l’open data qui postulent que toutes les données sont ouvertes sous leur forme brute dès leur production, les administrations choisissent encore quelles données ouvrir, comment les ouvrir, quand les publier, les mettre à jour et déterminent ce qu’elles contiennent. Le service public de la donnée garantit la continuité des données et leur adaptation aux besoins des usagers ce qui est indispensable pour développer des activités dont le modèle économique réclame la fiabilité des données. Néanmoins, au moment où j’écris ces lignes, il semblerait que les principes du service public de la donnée ne seront pas respectés par l’INSEE qui prévoit de suspendre la mise à disposition des fichiers quotidiens de la base SIRENE des entreprises sur data.gouv.fr[^fn12] pour basculer sur une interface de programmation (API) qui ne correspond pas à tous les usages. Pourtant, plusieurs miliers d’usagers ont développé des scripts qui se connectent à [data.gouv.fr](http://data.gouv.fr) et dépendent de ces fichiers pour assurer leur bon fonctionnement. Cette orientation a été signalée publiquement par des agents d’Etalab ce qui, en filigrane, rappelle la fragilité structurelle de l’ouverture des données publiques dans l’organisation administrative de l’Etat et du long travail restant à faire pour que les usagers déterminent les conditions dans lesquelles les données sont mises à disposition. 

En conclusion, nous avons pu mesurer le décalage qu’il existe entre les études macroéconomiques qui font de l’open data la nouvelle manne capable de créer des gisements colossaux de valeur et d’emploi et la réalité empirique. Il est en effet difficile d’observer ces résultats et nombreux sont les usagers qui font part de leur insatisfaction à l’égard des données mises à disposition. Plutôt que de promettre des retombées immédiates en terme d’emplois, mieux vaut rappeler que l’open data constitue un investissement de long terme dont les résultats ne pourront s’apprécier qu’après des années. C’est ce que montre bien ce schéma (Figure 4*)* tiré d’une étude allemande[^fn13] qui représente en trois grandes phases l’émergence des gains économiques de l’open data. 

![][Capturedécran2018-09-06à203058]

*Figure 4. Synthèse des phases de l’impact économique d’une politique d’open data.* 

        

L’étude part du principe que les entrepreneurs ne raisonnent généralement pas en identifiant des données et en trouvant des manières de les valoriser mais plutôt en identifiant un besoin ou un problème et en cherchant les données qui permettraient de le résoudre. Les gains ne peuvent pas donc être immédiats. Dans la première phase, celle de l’introduction, les couts (courbe bleue claire en bas) dépassent largement les gains pour le secteur public. On remarque que cette courbe décroit à travers les phases mais faiblement : pour que les bénéfices économiques de l’open data se réalisent, le travail sur les données doit se poursuivre avec les réutilisateurs pour en améliorer la qualité et la pertinence. Un investissement continu des acteurs publics dans l’open data est une condition essentielle de l’effet de levier économique attendu de l’ouverture des données. Dans la deuxième phase, le secteur privé commence à détecter des opportunités avec les données ouvertes et en tire profit. De faibles gains (courbe jaune) apparaissent et génèrent quelques revenus fiscaux (courbe bleue). Dans les deux premières phases, les gains sont essentiellement indirects (courbe orange) sous forme de gains d’efficacité et de nouvelles opportunités pour le secteur public comme nous le verrons dans le chapitre suivant. Enfin, dans une troisième phase, celle du **pay-off**, les données apportent des revenus au secteur privé et les revenus fiscaux dépassent très largement le cout pour l’administration. Cet effet multiplicateur ne se réalise qu’au terme d’un investissement de long terme du secteur public dans l’ouverture des données publiques et leur amélioration. Nous ne sommes peut-être que dans la phase d’introduction ou de croissance de l’open data, les bénéfices n’apparaitront que dans plusieurs années. Les estimations que j’ai mentionnées précédemment laissent pourtant penser que les emplois et les revenus fiscaux devraient apparaitre immédiatement. Or, ces chiffres pris pour argent comptant et confrontés à l’économie réelle peuvent mettre un terme aux politiques d’open data au motif d’une absence de résultats probants immédiats. 

[^fn1]: IDC, 2017, « European Data Market Study Final Report SMART 2013/006 », http://dataland-scape.eu/, consulté le 27 aout 2018.

[^fn2]: Portail européen de données, 2018, « The economic benefits of Open Data », https://www.europeandataportal.eu/fr/highlights/economic-benefits-open-data,  consulté le 24 août 2018.

[^fn3]: European Data Portal, 2015, « Creating Value through Open Data:
	
	Study on the Impact of Re-use of Public Data Resources », https://www.europeandataportal.eu/sites/default/files/edp\_creating\_value\_through\_open\_data\_0.pdf, consulté le 3 septembre 2018.

[^fn4]: EuDEco, 2017, « Report on the final model on the European data economy »,http://data-reuse.eu/wp content/up- loads/2017/09/Final-model-of-EuDEco-on-the-European-data-economy.pdf, consulté le 5 septembre 2018.

[^fn5]: Open Knowledge International, 2017, « Insights - Global Open Data Index », https://index.okfn.org/insights/, consulté le 5 septembre 2018. Traduction de l’extrait réalisée par l’auteur.

[^fn6]: Etalab, 2017, « Entretien avec Joël Gombin », https://github.com/etalab/user-research/blob/master/interviews/20170711-joel/index.md, consulté le 5 septembre 2018.

[^fn7]: Open Data Charter, 2015, « Principes », https://opendatacharter.net/principles-fr/, consulté 10 septembre 2018.

[^fn8]: Datactivist, 2017, « Qui a ouvert quoi ? le recensement des données des villes est maintenant ouvert »,
	
	https://medium.com/datactivist/qui-a-ouvert-quoi-le-recensement-des-donn%C3%A9es-des-villes-est-maintenant-ouvert-b7f697135c1f, consulté le 17 août 2018.

[^fn9]: Brouté, Vincent, 2017, « Mémorandum sur ce qu’il ne faut pas faire en Open Data, avec Datainfogreffe », https://medium.com/@neveldo/m%C3%A9morandum-sur-ce-quil-ne-faut-pas-faire-en-open-data-avec-datainfogreffe-d7798bace00e, consulté le 14 septembre 2018.

[^fn10]: Etalab, 2017, « Service public de la donnée de référence: c’est parti ! », https://www.etalab.gouv.fr/service-public-de-la-donnee-de-reference-cest-parti

[^fn11]: Etalab, 2018, « Pour une action publique transparente et collaborative : plan d’action national », https://www.etalab.gouv.fr/wp-content/uploads/2018/04/PlanOGP-FR-2018-2020-VF-FR.pdf, consulté le 3 septembre 2018.

[^fn12]: TeamOpenData, 2018, «  INSEE et SIRENE... changements à venir », https://teamopendata.org/t/insee-et-sirene-changements-a-venir/729/11, consulté le 14 septembre 2018.

[^fn13]: Preische, J, 2014, « Digitales Gold. Nutzen und Wertschöpfung durch Open Data für Berlin », https://www.technologiestiftung- berlin.de/fileadmin/daten/media/publikationen/140201\_Studie\_Digitales\_Gold\_Open\_Data.pdf, consulté le 5 septembre 2018. L’illustration est tirée du rapport *Creating Value through Open Data* cité précédemment.