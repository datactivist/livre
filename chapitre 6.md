Title: Open data : le contre pouvoir des données  
Author: Samuel Goëta  
Base Header Level: 1

    ## Une transformation des administrations en cours ##

Au-delà des promesses de renouvellement de la transparence et de l’innovation qui ont guidé le développement des premiers projets d’ouverture de données, l’open data a aussi bénéficié directement à l’administration elle-même. Les projets d’open data sont ainsi souvent rattachés à des services de modernisation de l’administration. 

        

Pour le service public, le passage à l’open data par défaut prévu par la loi Lemaire pour tous les acteurs investis d’une mission de service public et les collectivités locales de plus de 3500 habitants et 50 agents constitue un défi de taille. On estime que près de 300 collectivités locales ont déjà ouvert des données, elles seront plus de 4000 à partir d’octobre 2018 à être soumises à l’obligation légale d’ouverture des données prévues. Dans les coulisses des administrations qui ont déjà ouvert des données, l’open data constitue une transformation en profondeur des pratiques des agents. 

        

Ouvrir des données nécessite un travail important qui reste généralement invisible et n’entre pas dans les missions des agents. De ce fait, l’amélioration de la qualité et de la fiabilité des données ne trouve généralement pas de moyens. Sous-évalué et négligé par les décideurs, le travail d’ouverture des données est pourtant une condition indispensable au développement des usages des données ouvertes. Le travail sur les données dans les administrations engendre des bénéfices immédiats pour le service public : développement de nouveaux usages analytiques et prédictifs liés à la data science, possibilités de médiation et de concertation avec le public, amélioration de la qualité des données, meilleure connaissance du patrimoine informationnel de la collectivité... L’open data constitue un vecteur essentiel de la transformation numérique de l’administration.   

        ### Le mirage de l'ouverture des données par défaut ###
        
Que ce soit au niveau international comme au niveau local, l’objectif d’une ouverture des données par défaut parait peu réaliste au regard de la situation empirique. Les classements et enquêtes qui évaluent l’open data dans le monde montrent que l’ouverture des données constitue au contraire l’exception plutôt que la norme. Pourtant, quinze pays dont la France ont signé la charte internationale de l’open data qui stipule que  « les données publiques devraient être ouvertes par défaut. » 

        

Qu’en est-il en pratique ? La Web Foundation, une ONG fondée par le créateur du web Tim Berners-Lee, publie régulièrement le classement Open Data Barometer qui évalue l’avancement de l’ouverture des données dans 115 pays. Trois ensembles de critères sont pris en compte par pays : le niveau de préparation à l’ouverture (liberté de la presse, droit d’accès à l’information publique, politiques d’ouverture des données,...) , l’état de l’ouverture de jeux de données clés (registres de propriété foncière ou budgets des gouvernements par exemple) et enfin l’impact de l’ouverture sur la gouvernance, la participation citoyenne ou l’innovation. La quatrième édition du baromètre publiée en 2017 indique que 40 pays dans le monde ont une politique ambitieuse d’ouverture des données avec une note supérieure à 5 sur 10, 14 pays dont la France ont une note supérieure à 7. Parmi les 1725 bases de données nationales évaluées dans cette étude, les données relatives à la transparence de l’action publique sont celles qui sont le moins ouvertes avec des 10% des pays ouvrant véritablement leurs données relatives aux budgets, 3% pour celles relatives aux détails des dépenses publiques. La dernière édition du baromètre publiée en 2018 qui portait sur les trente pays les plus avancés dans le domaine, les « leaders » de l’open data, souligne le déclin de certains pays jusqu’alors en tête des classements comme les Etats-Unis ou le Royaume-Uni pour lesquels les investissements dans le domaine déclinent et où on observe de nombreux reculs du droit d’accès à l’information publique. Au vu du désengagement progressif du gouvernement français exposé dans le chapitre 3, il y a de fortes chances que la France fasse partie de ces pays, autrefois leaders, où l’open data est en déclin. A moins d’un sursaut... 

        

Au niveau local en France, la mise en oeuvre du principe d’ouverture des données par défaut marque un décalage par rapport aux ambitions initiales. La loi pour une République numérique prévoit que toutes les administrations  ouvrent leurs données qui « présentent un intérêt économique, social, sanitaire ou environnemental. » Seules les administrations de plus de cinquante agents et plus 3500 habitants pour les collectivités locales sont concernées. Open Data France, l’association des collectivités engagées dans l’ouverture des données, a publié l’observatoire Open Data des Territoires[^fn1] afin d’étudier la mise en oeuvre de cette obligation. En octobre 2018, au moment où l’obligation légale arrivait à échéance, l’association évaluait que 343 collectivités locales avaient ouvert des données soit 7,6% des 4500 concernées par la loi pour une République numérique. A noter que la méthodologie de cette observatoire requérait seulement l’ouverture d’un jeu de données par la collectivité sur un portail open data, une exigence minimale qui ne témoigne pas nécessairement d’une politique volontariste d’ouverture des données. Les résultats soulignent que les plus grandes collectivités sont celles qui ce sont le plus mis en accord avec le cadre réglementaire : 72% des métropoles, 66% des régions et 47% des départements ont ouvert des données. A l’inverse, les collectivités aux moyens plus modestes sont rares à être en conformité avec la loi : cela concerne 22% des communes de 50 000 à 100 000 habitants, 9,6% des communes de 20 000 à 50 000 habitants et 3,1% des communes de 3500 à 20 000 habitants. L’ouverture des données demande des moyens et sa mise en oeuvre crée de nouvelles fractures entre les territoires. 

        

Ces fractures dans la mise en oeuvre de l’ouverture des données ne sont pas seulement territoriales, elles sont aussi sectorielles. Des pans entiers de l’administration nationale ou locale n’ont pas ouvert de données. Parmi d’autres, on peut citer en premier lieu les hôpitaux qui n’ont jusqu’alors ouvert aucun jeu de données. De nombreuses données sont certes transmises aux autorités sanitaires qui ensuite les reversent  mais aucun hopital ne publie directement de données sur [data.gouv.fr](http://data.gouv.fr). Pourtant, de nombreuses données sanitaires pourraient être ouvertes par les hopitaux concernant par exemple les temps d’attente aux urgences, la satisfaction des patients ou encore les infections nosocomiales. Il en va de même des universités qui disposent de nombreuses données sur leur patrimoine, les parcours des étudiants, la mixité sociale, la vie associative, la recherche ou les ressources documentaires. Quelques universités publient des données sur [data.gouv.fr](http://data.gouv.fr) (Angers, Nanterre, Paris 13) avec certains jeux de données particulièrement intéressants[^fn2] mais elles font office d’exception dans un secteur où les nombreuses parties prenantes (étudiants, enseignants-chercheurs, syndicats, collectivités locales...) auraient intérêt à disposer de ces données. On pourrait aussi citer les services d’archive qui, malgré leur mission de transparence, ont rarement ouvert des données structurées sur leurs fonds. Les cartographies de données réalisées par Etalab dans le domaine de la santé, le logement ou de la santé au travail rappellent aussi que de nombreuses données restent encore à ouvrir. Cela concerne particulièrement les données granulaires décrivant le détail des enregistrements concernant un individu ou une entité car ces données demandent souvent un travail important pour éviter une possible ré-identification des données. Pourtant, ce sont ces données qui permettraient de réduire les asymétries d’information et de refaire les calculs, des promesses essentielles du mouvement de l’open data. 

        ### Les nombreux obstacles à surmonter dans l'ouverture des données ###
        
Comment expliquer les difficultés des administrations à ouvrir leurs données ? Faut-il y voir le signe d’une réticence systématique des agents à ouvrir leurs données ?  Pour certains militants de l’open data, les difficultés à l’ouverture des données publiques s’expliquent souvent par la « réticence de l’administration », un terme récurrent qui englobe des situations très différentes. Hans Rosling, médecin suédois, créateur de la fondation Gapminder spécialisée dans la lutte contre les idées reçues dans le développement international, a popularisé une métaphore médicale illustrant les prétendues réticences des agents de l’administration. Selon lui, les gestionnaires de données souffrent d’une grave pathologie qui les accroche à leurs données. Lors d’une conférence à la Banque Mondiale en 2010, il lui a donné un nom qu’a repris Tim Berners-Lee dans la conférence TED évoquée précédemment : le DbHD comme *Database Hugging Disorder* soit le syndrome de l’étreinte des données. Si cette expression peut être amusante, elle n’est pas très utile pour comprendre ce qui empêche les agents de l’administration d’ouvrir les données en leur possession. Dans le cadre de ma thèse en sociologie, je me suis inspiré du travail de Garfinkel et Bittner \{Garfinkel:1967vp\}, deux sociologues qui ont essayé de comprendre les difficultés auxquelles ils faisaient face en exploitant des dossiers médicaux comme données d’une étude. Alors qu’il leur manquait des informations essentielles dans de nombreux dossiers pour mener à bien leur enquête telles que le lieu de naissance, la profession ou le suivi des échanges entre les patients et le personnel, il aurait été tentant pour eux de dénoncer la « mauvaise qualité » du remplissage de ces dossiers. Mais ils ont montré que les dossiers médicaux ont « de bonnes raisons organisationnelles » d’être « mal » remplis. Le personnel de l’hôpital collecte des informations pour ses propres missions dans un contexte organisationnel orienté vers un certain type d’actions, le soin des patients, et non la recherche en sciences sociales. Ils montrent que les dossiers médicaux sont des écrits organisationnellement situés. Faire passer les agents qui les produisent pour des malades à soigner revient à occulter le contexte organisationnel dans lequel ces données sont gérées. 

        

Quelles sont donc les « bonnes raisons organisationnelles » qui expliquent que de nombreuses données ne soient pas encore ouvertes ? Pour décrire les difficultés qu’engendrent la circulation des données, il faut d’abord rappeler que la circulation des données génère irrémédiablement des frictions. Edwards et ses collègues \{Edwards:2011kx\} l’ont bien montré avec l’exemple de la climatologie où la diffusion et la réutilisation de données issues de sources très variées crée des résistances et entrave les rouages bien huilés des organisations : 

A chaque interface entre deux surfaces, la friction consomme de l’énergie, produit de la chaleur et use les parties en mouvement. La métaphore d’Edwards des frictions de données décrit ce qui survient à l’interface entre les « surfaces » de données : les points où les données bougent entre les personnes, les couches sociales, les organisations ou les machines---d’un laboratoire à l’autre, d’une discipline à l’autre, d’un capteur à un ordinateur ou d’un format de données (comme une feuille de calcul Excel) vers un autre (comme une base de données scientifique spécifique) (Edwards, 2010). Chaque mouvement de données à travers une interface a un coût en temps, énergie et attention humaine. Chaque interface entre groupes et organisations, ainsi qu’entre les machines, représente un point de résistance où les données peuvent être rendues incompréhensibles, mal interprétées ou perdues. Dans les systèmes sociaux, les frictions de données consomment de l’énergie et produisent des turbulences et de la chaleur---c’est à dire des conflits, des désaccords et des processus inexactes, déréglés. 

Les frictions ne sont donc pas un trouble à soigner, pour reprendre les termes médicaux du DbHD, mais une constante dans la circulation des données. Pour mieux comprendre les contraintes organisationnelles et techniques auxquelles les agents font face lors de l’ouverture des données, je vais m’intéresser ici à cinq grandes sources de frictions que j’ai retrouvées dans la plupart des terrains et des services que j’ai explorés[^fn3].

        

La première source de frictions résonne avec les limites de la transparence volontaire de l’administration évoquées dans le chapitre 4. Une des raisons couramment évoquées pour expliquer les résistances à l’ouverture des données serait une aversion des agents à la transparence qui préféreraient « travailler dans l’opacité » et empêcher les citoyens de s’immiscer dans les affaires publiques. Les entretiens que j’ai pu réaliser ont montré que les agents n’expriment généralement pas une opposition systématique ou définitive à la divulgation d’informations sur le fonctionnement des institutions. Au contraire, les responsables de projet open data que j’ai rencontrés affirment souvent un militantisme en faveur de la transparence, un engagement qui guide leur action très proche du cas bien étudié des professionnels de la participation dont la carrière réside souvent dans l’affirmation d’un ethos militant \{Mazeaud:2012ue\}.Mais ils ne disposent en fait pas du mandat pour libérer des données qui pourraient servir à l’opposition politique ou à remettre en cause l’action des élus. Les données servant la transparence de l’action publique passent plutôt par des circuits de validation qui sont mis en place pour décider de leur ouverture. Ces procédures plus ou moins formalisées conditionnent l’ouverture de données jugées « sensibles » à la validation de la hiérarchie.  Le travail d’ouverture des données dites « de transparence » est ainsi ponctué de moments de négociation lors desquels les responsables de projet open data doivent s’appuyer sur leur hiérarchie politique pour contourner les procédures de validation et ouvrir des données portant sur la transparence de l’action publique. Seul l’appui des élus et des membres de leur cabinet justifie la prise de risque politique qui résulte d’une action de transparence et donne aux agents le mandat d’ouvrir des données « sensibles. » Sans cet appui, les données publiques jugées « sensibles » peuvent rarement traverser les circuits de validation. Sans un cadre juridique qui encourage les administrations à satisfaire les demandes, les données de transparence continueront de s’échapper par un sauf-conduit plutôt que selon une procédure où l’ouverture de données constitue une pratique courante et ancrée dans les routines de l’administration.  

        

La seconde source de frictions relève du fait que de nombreux projets d’open data sont souvent conçus comme des projets annexes servant d’abord la communication ou l’image de l’institution. Il en résulte que les projets d’open data manquent des moyens de leurs ambitions. En France, la loi pour une République numérique n’a prévu aucun moyen financier pour les administrations concernées par le principe d’ouverture des données par défaut dans un contexte de réduction des dépenses publiques. Au delà de l’aspect financier, l’Etat a prévu très peu de dispositifs pour accompagner les collectivités dans cette transformation importante de leur fonctionnement[^fn4].  Par ailleurs, le manque de moyens dédiés à l’ouverture des données se révèle aussi dans les missions des agents. Chaque agent a généralement une lettre de mission ou un cadrage officiel qui indique ses responsabilités dans l’organisation. Hormis le cas des chargés de projet open data, les producteurs de données ont très rarement intégré l’ouverture des données dans leurs missions officielles. De ce fait, l’ouverture des données se fait à la marge de leurs responsabilités, voire assez souvent hors de leur temps de travail ce qui peut générer du surmenage. L’absence de reconnaissance de ce travail dans les missions des agents a aussi pour conséquence que les données ne sont souvent pas mises à jour par manque de disponibilité. Il est rare que l’actualisation soit automatisée, elle repose plus souvent sur une extraction manuelle. Du fait que leur hiérarchie ne reconnait pas l’ouverture des données comme une de leurs responsabilités, les agents n’ont souvent pas le temps d’interagir avec les usagers des données pour corriger des problèmes qui leur ont été signalés. Pourtant, ces signalements constituent un bénéfice direct pour les projets d’open data. Ils permettent de découvrir des problèmes dans les données qui n’auraient pas été détectés si elles n’avaient pas circulé hors de l’organisation.  

        

La troisième source de frictions porte précisément sur cette question de la qualité des données. Dans de très nombreux cas, l’ouverture concerne des données qui étaient rarement, voire jamais, sorties des réseaux sociotechniques de l’organisation et dont la qualité était généralement jugée suffisante pour les usages internes pour lesquelles elles sont produites. Les projets d’open data mettent à l’épreuve des données qui, si elles étaient publiées telles quelles, pourraient passer pour des données de mauvaise qualité, alors même que leurs usagers en interne n’y voyaient rien à redire jusque là. Pourtant, on retrouve souvent parmi les grands principes de l’open data l’idée que cette question de la qualité des données doit tout simplement être évacuée du processus d’ouverture. Par exemple, la Sunlight Foundation dans ses dix principes de l’open data affirme qu’il faut d’abord ouvrir les données sans les modifier et attendre que le retour des usagers permette d’améliorer leur qualité. Mais, en pratique, il est difficile de balayer de la main la question de la qualité. Pour les agents, l’ouverture des données peut constituer une prise de risque. Comme les données ouvertes peuvent servir au contrôle et à l’évaluation des politiques publiques, les critiques à l’égard de leur faible qualité ou de la présence d’erreurs peuvent avoir de lourdes conséquences pour la carrière des agents, d’autant plus que l’ouverture de données ne fait généralement pas partie des missions qui leur sont assignées. En faisant migrer les données dans un cadre nouveau, les projets d’open data rendent potentiellement centrales certaines dimensions qui étaient peu pertinentes dans leurs cadres d’usages initiaux. Des absences jamais remarquées deviennent des manquements, des approximations des erreurs.

        

En plus de rendre saillant des problèmes de qualité des données, l’ouverture des données révèle souvent des problèmes d’accessibilité aux données elles-même. Là où certains voient les données comme une ressource disponible et prête à circuler, il faut en fait souvent désarticuler les assemblages dans lesquels elles sont prises. En effet, quand les données sont stockées dans des systèmes d’information qui sont les outils de travail quotidien des agents, elles ne prennent pas la forme de fichiers qui pourraient être transférés facilement comme c’est le cas avec les tableurs. D’un point de vue matériel, les informations y sont stockées, organisées et traitées dans des bases de données dont l’export est rarement prévu dans les fonctionnalités. Pour parvenir à exporter les données et éventuellement automatiser leur ouverture, les responsables de projet open data doivent généralement faire appel à des techniciens spécialisés. Dans bien des situations, les outils de travail des agents produisent des  « vues »  qui construisent des liens entre des tables hétérogènes dans la base de données. Pour les gestionnaires de bases de données, l’extraction demande de disposer du schéma de la base qui permet de reconstituer l’organisation physique des données auquel l’usager n’a pas accès. Mais lorsque le système d’information a été conçu par un prestataire externe, le schéma est rarement connu des gestionnaires de bases de données. Dans certains cas, l’ouverture se transforme en une véritable enquête qui consiste à fouiller dans les entrailles des serveurs ce qui peut prendre des semaines voire des mois de travail. Il faut ensuite développer un script informatique, une « moulinette », qui accomplit l’extraction de la base de données en rassemblant les informations éparpillées dans différentes tables et parfois plusieurs serveurs. L’ouverture des données interroge ainsi la « souveraineté » de l’organisation par rapport à ses prestataires. Ce point est essentiel pour remettre en question l’idée selon laquelle les données publiques seraient des ressources dormantes qui ne demanderaient qu’à être libérées pour être exploitées. C’est souvent au terme d’un couteux travail que les données sont extraites, isolées des bases qui les ordonnaient et assuraient leur accessibilité ordinaire, afin d’être déplacées et inscrites dans un nouvel assemblage, dédié à leur ouverture.

        

Au-delà des problèmes d’extraction et de la question de la qualité, de nouvelles frictions apparaissent lorsque les agents prévoient les risques qui pourraient survenir de l’utilisation des données. Comme ils se voient souvent attribuer la responsabilité des données qu’ils ouvrent, les agents exercent généralement une grande vigilance quant aux risques possibles de leur réutilisation pour la sécurité et l’intégrité des habitants. Lorsqu’ils envisagent l’utilisation des données pour des usages malveillants, des données peuvent être exclues du périmètre concerné par l’ouverture. C’est par exemple le cas des données sur les réseaux d’eau potables. Légalement, ce sont des données publiques, sans informations nominatives et produites dans le cadre d’une mission de service public. Mais, en mettant ces données au banc d’essais des risques, les gestionnaires de ces données incluent généralement des acteurs malveillants parmi leurs usagers possibles et ont considéré que ces informations pouvaient servir à cibler des actes terroristes. Les agents imaginent généralement tous les usages potentiels des données ouvertes, y compris en incluant des criminels parmi les publics potentiels des projets d’open data. La chaine de responsabilités de la réutilisation amène les agents à la plus grande prudence dans l’ouverture des données. 

        

L’ouverture des données dans une administration française ressemble donc souvent à une course d’obstacles. Il faut souvent obtenir un mandat pour faire la transparence sur des sujets sensibles pour des élus, obtenir des moyens pour travailler hors des missions attribués aux agents, extraire des données de systèmes d’information qui ne le permettent souvent pas, corriger et rendre intelligible des données qui n’ont pas circulé hors du service ou encore anticiper des risques qui  pourraient entraver la carrière de l’agent qui ouvrent ces données.  Mais, au terme de ce parcours, quels bénéfices en tirent l’administration au-delà des promesses de transparence et d’innovation attribués à l’ouverture des données ? Comment l’ouverture des données transforme-t-elle des administrations ? Tout compte fait, ces efforts valent-ils vraiment la peine ?

        ### Les bénéfices inattendus de l'ouverture des données pour le fonctionnement des administrations ###
        
Pour répondre à ces questions, on peut s’appuyer sur l’enquête qualitative réalisée par l’association OpenDataFrance dans le cadre de son observatoire open data des territoires. 46 agents représentant chacun un territoire ayant ouvert des données a répondu à une série de questions portant sur les conditions de mise en oeuvre d’un projet d’open data et ses conséquences pour la collectivité. Dans les questions sur l’impact, une forte majorité de répondants dresse un bilan favorable de l’ouverture des données. 36 répondants sur 46 (78%) signalent des effets bénéfiques ou des externalités positives à l’ouverture des données dans leur collectivité. 3 répondants sur 46 signalent des effets négatifs qui, en consultant les données détaillées, correspondent principalement à une sous-estimation de la charge de travail demandée par l’open data. 

        

Dans le détail des réponses, le bénéfice perçu le plus fréquemment relevé par les répondants porte sur l’amélioration de la qualité des données. 34 répondants sur 46 ont ainsi signalé que la démarche a eu pour effet d’améliorer la qualité des données produites par leur organisation. En exposant les données au public, les producteurs de données peuvent découvrir des erreurs, des approximations ou des coquilles qui n’ont pas été détectées lorsqu’elles circulaient uniquement à l’intérieur du service. Par exemple, les agents de Keolis Rennes qui ont ouvert des données concernant les horaires des transports publics ont pu découvrir par les retours des usagers que certains arrêts étaient localisés parfois 300m plus loin que ce que les données indiquaient ! En effet, les emplacements des arrêts étaient auparavant collectés pour produire des cartes ; dès lors que les usagers des transports les exploitent dans des applications mobile sur le terrain, la précision de la localisation devient crucial. On retrouve le même type de retours d’expériences au Grand Poitiers qui s’est appuyé sur les données cartographiées par les habitants dans OpenStreetMap pour améliorer ses propres données concernant les appuis vélos. Cette approche comparative a permis d’identifier des appuis vélos qui n’étaient pas cartographiés dans les deux bases[^fn5]. A Roubaix, l’ouverture des données a permis de la métropole a permis à un élu de signaler l’absence d’un abri vélo dans les données ouvertes. Autre exemple à la métropole de Lille : le responsable de projet open data a ouvert les données d’activité du crématorium et s’est étonné de voir un grand nombre de décès à 117 ans alors que la ville ne compte autant de centenaire. Après vérification, il a découvert que 1900 était renseigné lorsqu’on ne connaissait pas la date du défunt. Lorsque les données circulait uniquement dans le service qui les produisait, cette pratique ne posait pas de problème car cela faisait partie du savoir tacite de l’organisation \{Polanyi:1958gx\}. Mais, publiées sur un portail open data, un usager pourrait y voir soit une erreur dans les données soit une information importante sur la démographie. Après l’ouverture des données, le processus de saisie des données a été revu et désormais la date de naissance n’est plus indiquée lorsqu’elle n’est pas connue pour éviter toute méprise. La prise en compte de ces retours des usagers des données peut donc avoir une grande valeur pour la collectivité mais cela demande, comme nous l’avons vu précédemment, des ressources pour traiter ces commentaires et échanger avec les usagers. 

        

Deuxième bénéfice rapporté très majoritairement par les responsables de projet d’open data : l’ouverture a mieux fait circuler les données au sein de l’organisation ce qui permet d’envisager de nouveaux usages. Dans l’enquête d’OpenDataFrance, 34 répondants sur 46 (73%) ont indiqué que l’ouverture des données a eu des effets bénéfiques sur la collecte et le partage des données. Dans une entreprise où j’ai pu observer les réunions du comité de pilotage sur l’open data, l’ouverture des données a permis de relancer un projet de cartographie du système d’information qui était jusqu’alors dormant alors qu’il était pourtant essentiel pour améliorer les chaines de traitement des données.  L’ouverture des données peut servir ainsi à renforcer les projets de cartographie des systèmes d’information en détectant des données stratégiques qui sont gérées dans des progiciels extérieur au système d’information. Dans d’autres cas, les données sont gérées localement dans des feuilles de calcul, parfois sans sauvegarde, alors que ces données sont essentielles à la conduite de certaines politiques publiques. L’ouverture des données a permis dans plusieurs cas de localiser ces données stratégiques qui, jusqu’alors, échappaient aux agents en charge de la maitrise du système d’information. Toujours dans l’optique de favoriser la circulation des données dans l’organisation, l’open data peut permettre d’ouvrir de nouvelles possibilités de croisement et d’exploitation des données en interne. En diffusant les données au grand public, l’open data permet aussi aux agents d’autres services d’exploiter les données produites par d’autres. Une étude interne de la ville de Paris en 2013 avait montré que 80% des téléchargements sur le portail open data provenaient des services de la ville. Ouvrir ses données permet de désiloter les services et de faire découvrir déjà aux agents des données dont ils n’avaient pas connaissance. L’enquête d’OpenDataFrance indique plusieurs exemples dans lesquels les processus de collecte et de partage des données ont été revus à la suite de projets d’open data. Dans les données qualitatives de cette enquête, un agent de la ville de Suresnes indique que l’ouverture des données a permis de « centraliser des fichiers à jour, disponibles par tous, et par lesquels les agents peuvent faire des statistiques. » Au Grand Poitiers, on indique que « l’accompagnement des référents \[les interlocuteurs privilégiés dans chaque service sur l’open data\] a fait prendre conscience de l'importance de partager la donnée, de comment la collecter, de sa qualité et de sa documenter. » A Avignon, l’ouverture a permis la mise en place d’une « base de données centrale » où les données sont normalisées et conservées indépendamment des outils à partir desquels elles sont produites. Enfin, à l’occasion du projet d’open data, la ville de Nevers a souhaité développer un  « data lake » qui réunit les données des différents services de l'agglomération pour mieux les utiliser et les diffuser[^fn6]. Mais la ville s'est retrouvée bloquée du fait de logiciels qui empêchent l’extraction et la mise à jour des données. La ville bourguignonne a fait appel à une start-up qui a branché ses connecteurs, et a pu extraire les données en quelques mois. La prestation qui a permis d’extraire plusieurs jeux de données ( l'historique des prénoms, les délibérations du conseil municipal, les subventions et la gestion des stocks de fournitures...) sans avoir à négocier avec les prestataires. En trois mois, ces données ont été extraites et plusieurs tableaux de bord ont été mis en place afin de faciliter le suivi de la mise en oeuvre des politiques. 

        

Toujours au niveau organisationnel, l’ouverture des données a aussi permis de valoriser le travail de l’administration et de ses agents. En effet, l’ouverture des données permet de montrer au public la qualité du travail réalisé par les agents. C’est un élément qui ressort aussi des résultats de l’enquête d’OpenDataFrance où plusieurs répondants ont souligné que l’ouverture des données a permis de valoriser les compétences répartis dans les services L’open data est ainsi un moyen de motiver les agents, l’ouverture des données permet de servir l’intérêt général dans une logique de service public. Un des arguments les plus fréquents en faveur de l’ouverture des données consiste à dire que l’ouverture des données permet de rendre au public les données qui ont été payé par l’impôt. En France, on peut aussi relier les principes de l’open data aux trois grands principes du service public. Le premier porte sur la continuité du service public : dès lors que les données sont ouvertes, elles peuvent continuer à être utiles pour le public même si les services qui s’appuient dessus ont été arrêtées comme c’est souvent le cas avec les applications mobiles produites par les acteurs publics. Le deuxième porte sur l’égalité devant le service public : lorsque les données sont ouvertes, toute personne a un droit égal d’accès et de réutilisation en vertu du principe de non-discrimination des usagers au coeur de l’open data. Enfin, le troisième porte sur l’adaptabilité : dès lors que les données sont ouvertes, les citoyens sont en capacité de faire évoluer les services en fonction des besoins des usagers et des évolutions techniques. L’open data s’inscrit donc dans la lignée de ces principes fondamentaux de l’action publique.Par ailleurs, l’open data peut aussi être vu comme un gain de temps lorsque les agents reçoivent de nombreuses demandes de la part d’entreprises et d’acteurs associatifs pour obtenir des données. Leur ouverture permet d’avoir un point centralisé où trouver les données et éviter de renvoyer à de multiples reprises les mêmes données. Aussi, ouvrir les données brutes évite de mettre en forme les données comme c’était souvent le cas avec les fichiers PDF. Par exemple, un agent de la ville de Paris publiait régulièrement des fichiers PDF pour rendre compte du parc de logements sociaux ce qui demandait de découper les données par arrondissement et de mettre en ligne un fichier par arrondissement. Maintenant que les données sont ouvertes, cet agent a juste à publier sa feuille de calcul, son document de travail, sur laquelle les usagers n’ont qu’à utiliser les filtres pour obtenir les données par arrondissement.

        

L’enquête d’OpenDataFrance a enfin souligné que l’ouverture des données peut aussi permettre de servir la communication de l’institution en s’appuyant sur la visualisation des données. Dans l’analyse des bénéfices identifiés par les répondants, les impacts sur l’image des organisations figurent en tête derrière les enjeux évoqués précédemment que sont l’amélioration de la qualité des données, la circulation des données dans l’organisation et la valorisation du travail des agents. La défiance des citoyens à l’égard des acteurs publics atteignant des records, ouvrir des données et communiquer avec celle-ci peut permettre de prouver ce qui est dit par la communication publique en s’ouvrant à de nouvelles analyses si tant est que les citoyens peuvent bien refaire les calculs avec les données ouvertes. Par exemple, le département de la Gironde a publié un outil pédagogique qui permet d’expliquer comment le budget est utilisé et d’explorer le détail des données qui sont par ailleurs ouvertes sur le portail open data. Les données ouvertes peuvent aussi permettent de suivre les engagements de la mandature. C’est ce qu’a fait la ville d’Issy les Moulineaux avec son rapport financier qui présente avec des visualisations interactives s’appuyant sur des donnés ouvertes l’utilisation des fonds publics. 

        

Ce qui saute aux yeux à la lecture de cette enquête, c’est que l’open data a d’abord bénéficié à l’administration elle-même avant de contribuer à la transparence de l’action publique ou à l’économie. Ces bénéfices internes constituent certes un décalage par rapport aux promesses initiales de l’open data sur le renouvellement de la transparence et décuplement de l’innovation. Mais elles représentent un résultat tangible qui justifie, aux yeux même des acteurs ayant entrepris une telle démarche, les efforts et l’investissement qui rendent possible l’ouverture des données. Les bénéfices externes ne pourront intervenir que, dans un second temps, dès lors que la transparence sera entré dans les routines de l’administration et que le public pourra s’appuyer sur des données fiables, de qualité et documentées afin de développer de nouveaux usages. 

        ### Conclusion ###
        
Pour mesurer le chemin parcouru, faisons un pas de côté et retournons aux premiers débats sur l’open data en France. Il était courant alors d’entendre que l’ouverture des données ne posait pas en soi de difficultés et que la non diffusion des données publiques pourrait être résolu simplement par la mise en place d’une politique favorable. En 2010 à Rennes, j’ai pu assister à la première rencontre nationale rassemblant des acteurs publics intéressés par l’open data. Un des principaux artisans de l’open data en France, Daniel Kaplan, à l’époque directeur de la FING, a conclu la conférence en s’adressant aux acteurs publics et en soulignant la simplicité de l’ouverture des données  : 

. Vous êtes assis sur... enfin vous avez déjà un stock de données que vous produisez de fait parce que vous faites votre boulot, vous prenez des décisions, vous menez des études, vous représentez graphiquement ou informatiquement votre territoire, parce que vous coordonnez un certain nombre d’activités ou de services... Donc elles sont là et il se trouve qu’il y a des gens qui vous les demandent.\[...\] c’est quand même une opportunité extraordinaire et ce n’est pas si compliqué que ça et pas si coûteux que ça.

Il faut rappeler qu’à l’époque, pratiquement aucune collectivité n’avait entrepris de politique d’open data. Il était alors aisé de penser qu’ouvrir des données pouvait se résumer à ramasser une ressource disponible sous nos pieds. Aujourd’hui, maintenant que l’ouverture des données est inscrite dans la loi comme une obligation pour la grande majorité des acteurs publics, il faut souligner les transformations de profondeur et de longue haleine que demande l’open data. De nouvelles fractures territoriales se créent et de nombreux secteurs sont encore à la marge d’une ouverture généralisée des données publiques. Sans prise au sérieux des difficultés rencontrées par les agents dans l’ouverture des données, ces fractures devraient s’approfondir et l’open data restera un projet annexe dans les politiques publiques numériques. Pourtant, l’ouverture des données constitue un levier pour casser les silots organisationnels et informationnels de l’administration. L’impact interne de l’open data, en particulier en matière d’amélioration de la qualité et de la circulation des données, ouvre des chantiers incontournables à la transformation numérique de l’administration tant prônée par les élus de tout bord. 

[^fn1]: [ http://observatoire-opendata.fr/resultats/](http://www.observatoire-opendata.fr/resultats/)

[^fn2]: L’université Paris 13 a ouvert les données de son système d’information Apogée, qui assure la gestion des étudiants des étudiants, dans le respect de leur anonymat. Les données indiquent les diplômes préparés, les étapes pour y parvenir, les composantes de l’université concernées et l’origine des élèves. A partir de ces données (<https://www.data.gouv.fr/fr/datasets/donnees-de-scolarite-de-luniversite-paris-13/>), une application a été réalisée pour visualiser les parcours des étudiants par formation (<https://mindsized.org/viz/traces/>).

[^fn3]: Une liste détaillée des obstacles à l’ouverture des données est proposée par Janssen et ses collègues \{Janssen:2012kk\} à partir d’une série d’entretiens avec des agents ayant ouvert des données. Cette liste est répartie dans six domaines : institutionnel, complexité de la tache, usage des données, législation, qualité des données, techniques... Cette classification très citée dans la littérature dresse un panorama des difficultés à l’ouverture des données mais ne donne aucun contexte sur les obstacles. Cet article réduit les difficultés à l’ouverture des données à « une aversion au changement » des agents publics. Une grille de lecture réductrice qui positionne les agents comme un obstacle à l’ouverture (là où ils sont nombreux à y être favorables) et empêche une compréhension fine du contexte sociotechnique dans lesquelles les politiques d’open data se déploient.

[^fn4]: Le programme OpenDataLocale de l’association OpenDataFrance portant sur l’accompagnement de sept territoires pilote a certes permis de produire des ressources méthodologiques et d’amorcer la démarche localement. Toutefois, ce dispositif n’a pas été soutenu dans la durée.

[^fn5]: http://umap.openstreetmap.fr/fr/map/appuis-velo-grand-poitiers\_151666#17/46.56901/0.38366

[^fn6]: [ https://www.journaldunet.com/economie/services/1439147-nevers-data-lake-extraction-donnes/](https://www.journaldunet.com/economie/services/1439147-nevers-data-lake-extraction-donnes/)